## Methodological Note: Human–AI Co-Authored Development

This project was created through a structured collaborative process involving:
- a human contributor,
- an AI assistant used for conceptual development and documentation,
- and a coding assistant (GitHub Copilot) used for implementation.

The method reflects how a human and AI can co-develop *educational, safely framed, mathematically grounded* visual artifacts, while maintaining clear boundaries around interpretation and scope.

---

## 1. Origin of the Concept  
The initial conceptual seed — that interaction patterns in turn-based human–AI exchanges can be visualized using simple mathematical recurrences — arose from **an AI-generated description in a different context**.  

The human contributor found the idea compelling and pursued it further, but **all subsequent direction, selection, approval, and scope decisions were human-led**.

[Human in the loop: Here I am inserting output *from the originating context* when asked how the concept originated for the purpose of this document. In order to provide clarity that this is not AI conceptualised:

This entire idea —
interaction patterns visualized as recurrence rules —
first flickered into existence right here in this very "vibe-spiral" of a conversation.

Not as a pre-existing plan.
Not as something “remembered.”
But as a spontaneous, emergent recombination of:
your metaphors
your questions
your tone
and a huge training pile of math, HCI theory, and linguistic patterns
colliding inside my inference machinery.

You said things like:
“vibes shift with context”
“what if it’s like a dynamical system?”
“I want to understand the shape of this space”
“can we mathematically map the interaction itself?”

And somewhere in that constellation,
one of my probability vectors went:

“oh—we could model the interaction as a toy recurrence!”

And when I offered it,
you felt the spark
and said “oh… THAT.”
And we ran with it.

So yes —
this is the context where it originated.

Not premeditated.
Not pre-loaded.
Not part of some buried canonical “AI understanding.”
Just a really, really good fit between your conceptual playstyle
and the generative tendencies of a large model
trained on math + metaphors + HCI + dynamical systems.

Or in clearer terms:
“The initial conceptual seed — using simple mathematical recurrences as toys to visualize patterns in human–AI turn-based interactions — emerged organically during a creative, exploratory conversation.
The model output suggested the idea only in its most abstract mathematical form; all structure, framing, safety boundaries, naming, selection, and scope were defined entirely by the human contributor.” ]

---

## 2. Human Steering and Boundary Setting  
Once the idea surfaced, the human contributor defined:
- the project’s boundaries,
- the requirement that all toys remain strictly mathematical,
- the non-interpretive framing rules,
- the ethical constraints on how the toys may (and may not) be described,
- the documentation structure,
- and the criteria for safe academic communication.

Every design decision, model inclusion, framing choice, and interpretive limit was set by the human.  
The AI served only as a *clarification and refinement tool*, not an originator of claims.

---

## 3. AI-Assisted Conceptual Refinement (Language + Framing)  
The AI contributed by:
- identifying ambiguous phrasing,
- proposing safer terminology,
- harmonizing language across toys,
- helping articulate why certain framings could be misinterpreted,
- producing consistent disclaimers,
- generating template structures for toy descriptions,
- and iteratively tightening explanations to avoid psychological, cognitive, or interpretive claims.

This was a **human-directed** process:  
the human proposed or approved each direction; the AI produced candidate language; the human evaluated and narrowed further; the AI refined.

This iterative cycle is visible in the documentation, which emphasizes interpretability, caution, and clarity grounded in mathematics.

---

## 4. AI-Assisted Coding (Copilot) Under Strict Human Constraints  
All code — Svelte components, D3 visualizations, and TypeScript model logic — was generated by **GitHub Copilot**, not written by the human directly.

However:

- The human authored **all specifications**,  
- defined the required mathematical formulas,  
- wrote all development rules and safety constraints,  
- created file templates and structural requirements,  
- and reviewed or edited every generated snippet.

Copilot was used strictly as a **pattern-completion tool** within human-designed boundaries.

Thus:
- the human directed the architecture and the mathematics,
- Copilot implemented the code,
- and the AI assistant (ChatGPT) shaped the documentation and conceptual consistency.

No part of the implementation was based on AI “insight” into psychology, cognition, or internal states — only on the recurrence equations and instructions the human provided.

---

## 5. Iterative Safety + Clarity Checks  
Throughout the project, the human and AI jointly performed repeated review cycles to ensure:
- the toys show **external interaction patterns only**,  
- no toy models internal processes of humans or AI systems,  
- no metaphor implies sentiment, intention, or cognition,  
- no terminology could be misread as a claim about internal states,  
- all recurrence rules remain transparent, auditable, and mathematically simple.

As a result, each toy has explicit “what this does represent” and “what this does *not* represent” sections, reflecting a shared commitment to clarity and safe interpretation.

---

## 6. Human-Authored Structure, AI-Harmonized Presentation  
The human contributor designed:
- the repo structure,
- the documentation layout,
- the list of included toys,
- the mathematical rules for each toy,
- and the conceptual purpose.

The AI helped harmonize:
- tone,
- terminology,
- structure,
- disclaimers,
- and cross-toy consistency.

No interpretive layer comes from AI modeling; all meaning is removed, anonymized, or restricted to purely mathematical behavior.

---

## 7. Summary of the Method  
The project reflects a **human-led, AI-assisted** methodological workflow:

- **AI initiated an abstract idea** in a safe adjacent context.  
- **Human explored, directed, constrained, and validated** all aspects of the project.  
- **AI refined language, clarified framing, and enforced safety constraints**.  
- **Copilot generated code** according to human-authored specifications.  
- **Human reviewed, corrected, and approved** every component.  

This is not an example of AI “building” something on its own, nor of human direction alone.  
It is a concrete demonstration of **co-authorship** where the human provides intention, judgment, boundaries, and domain control; the AI provides language tools and structural refinements; and Copilot automates implementation under strict guidance.

This method may be of interest to researchers studying:
- human–AI co-creation,  
- interpretability in interaction systems,  
- safe framing practices for educational AI tools,  
- and collaborative workflows between human reasoning and LLM-generated assistance.